# ATP Match Outcome Prediction â€” *A crownâ€‘jewel dataset + a model that really delivers*

> **Tagline:** *Endâ€‘toâ€‘end ETL + scalable feature engineering + calibrated XGBoost delivering stateâ€‘ofâ€‘theâ€‘art tennis match win probabilities. Built for reproducibility. Designed for sports analytics.*

---

## âœ¨ What is this?

This repository brings together the **entire workflow** to predict ATP match outcomes from 1999 to today:
**scraping â†’ parsing â†’ SQL staging â†’ ETL/feature engineering â†’ yearâ€‘wise validation â†’ calibration â†’ holdâ€‘out evaluation** and, most importantly, a **curated longitudinal dataset** thatâ€™s the projectâ€™s **crown jewel**.

You get two deliverables:

1. **A rich, longâ€‘horizon dataset** (the *jewel*): 1999â€“2025 coverage, with **real competitive context** features (rest, travel, adaptation to surface & indoor, prior load) for **both players**.
2. **A calibrated XGBoost model** that outputs realistic win probabilities and strong outâ€‘ofâ€‘sample metrics.

If you work in **sports analytics**, **quantitative sports trading**, **scouting**, or **ML R&D for sports**, this repo offers **productionâ€‘grade building blocks** backed by **highâ€‘quality data**.

---

## ğŸ”‘ Why this project stands out

* **Serious, reproducible ETL.** Temporal ordering is enforced, leakage is avoided, and the unit of analysis (matchâ€“player) is consistent across time.
* **Unique â€œfatigue & adaptationâ€ features** (for both player roles):

  * Days/weeks since previous tournament.
  * Discrete signals: *backâ€‘toâ€‘back*, *twoâ€‘weeks gap*, *long rest*.
  * Country / continent / surface / indoorâ€“outdoor changes.
  * **Redâ€‘eye risk** (intercontinental + consecutive week).
  * **Travel fatigue score** (composite).
* **Coldâ€‘start preâ€‘1999** with historical seed (Jeff Sackmann): last seen date & tournament prior to 1999, and round normalization (**ERâ†’R128**) for phase alignment.
* **Validation that mirrors reality**:

  * **Yearâ€‘wise crossâ€‘validation (2000â€“2025)** with an **`id` guarantee** (both rows of a match stay together).
  * **OOF (2000â€“2022)** to train a **calibrated probability** model via isotonic regression.
  * **Holdâ€‘out 2023â€“2025**, also broken down by tournament type.
* **Calibrated probabilities** + **costâ€‘optimal thresholding** for decisionâ€‘ready outputs.

---

## ğŸ† Results (executive summary)

> Figures come from the notebook with embedded outputs (`MODEL/model1.ipynb`) and are indicative for this data snapshot and setup.

* **Yearâ€‘wise CV 2000â€“2025** (26 folds, `id` leakageâ€‘safe):
  **AUC â‰ˆ 0.964 | LogLoss â‰ˆ 0.224 | Brier â‰ˆ 0.072 | Accuracy â‰ˆ 0.89**
* **OOF 2000â€“2022** (for isotonic calibration):
  **AUC â‰ˆ 0.972 | LogLoss â‰ˆ 0.210 | Brier â‰ˆ 0.068**
* **Holdâ€‘out 2023â€“2025** (calibrated probabilities):
  **AUC â‰ˆ 0.915 | LogLoss â‰ˆ 0.379 | Brier â‰ˆ 0.120 | Accuracy â‰ˆ 0.821**

**Bottom line:** the system **generalizes** and the **probabilities are calibrated**â€”a must for riskâ€‘aware decisioning.

---

## ğŸ—‚ï¸ Repository structure (actual file names)

```
ATP-Match-Outcome-Prediction/
â”œâ”€ Data_Example/
â”‚  â””â”€ sample.csv                      # Tiny sample for quick inspection
â”‚
â”œâ”€ ETL/
â”‚  â”œâ”€ Extractor/
â”‚  â”‚  â”œâ”€ MatchesATPExtractor.py
â”‚  â”‚  â”œâ”€ MatchesBaseExtractor.py
â”‚  â”‚  â”œâ”€ PlayersATPExtractor.py
â”‚  â”‚  â”œâ”€ StatsATPExtractor.py
â”‚  â”‚  â”œâ”€ TournamentsATPExtractor.py
â”‚  â”‚  â”œâ”€ base_extractor.py
|  |  â”œâ”€ constants.py
â”‚  â”‚  â””â”€ runner.py
â”‚  â”‚
â”‚  â”œâ”€ Load/
â”‚  â”‚  â””â”€ CreateData.R                 # R loader/assembler
â”‚  â”‚
â”‚  â””â”€ SQL/
â”‚     â”œâ”€ Procedures&Functions/        # Stored procs & UDFs (sf_* / sp_*)
â”‚     â”œâ”€ Tables/
â”‚     â”‚  â””â”€ Staging/
|     |  |     â”œâ”€ stg_match_scores.sql
|     |  |     â”œâ”€ stg_match_stats.sql
|     |  |     â”œâ”€ stg_matches.sql
|     |  |     â”œâ”€ stg_players.sql
|     |  |     â”œâ”€ stg_teams.sql
|     |  |     â””â”€ stg_tournaments.sql
â”‚     â”‚  â”œâ”€ atp_matches.sql
â”‚     â”‚  â”œâ”€ atp_matches_enriched.sql
â”‚     â”‚  â”œâ”€ atp_players.sql
â”‚     â”‚  â”œâ”€ atp_tournaments.sql
â”‚     â”‚  â”œâ”€ countries.sql
â”‚     â”‚  â”œâ”€ indoor_outdoor.sql
â”‚     â”‚  â”œâ”€ match_scores_adjustments.sql
â”‚     â”‚  â”œâ”€ player_points.sql
â”‚     â”‚  â”œâ”€ points_rulebook.sql
â”‚     â”‚  â”œâ”€ points_rules.sql
â”‚     â”‚  â”œâ”€ series.sql
â”‚     â”‚  â”œâ”€ series_category.sql
â”‚     â”‚  â”œâ”€ stadies.sql            # (kept asâ€‘is)
â”‚     â”‚  â””â”€ surfaces.sql
â”‚     â””â”€ views/
â”‚        â”œâ”€ vw_atp_matches.sql
â”‚        â””â”€ vw_player_stats.sql
â”‚
â”œâ”€ Transform/
â”‚  â”œâ”€ Ranking Scrapping/
â”‚  â”‚  â”œâ”€ Ranking_scrapping.py         # Headless HTML fetch from atptour.com
â”‚  â”‚  â”œâ”€ rankings_to_csv.py           # BeautifulSoup â†’ perâ€‘date rankings CSV
â”‚  â”‚  â”œâ”€ DataTransform1.R
â”‚  â”‚  â”œâ”€ DataTransform2.R
â”‚  â”‚  â”œâ”€ DataTransform3.R
â”‚  â”‚  â”œâ”€ DataTransform4.R
â”‚  â”‚  â”œâ”€ DataTransform5_1.R
â”‚  â”‚  â”œâ”€ DataTransform6.R
â”‚  â”‚  â”œâ”€ DataTransform6_1.R
â”‚  â”‚  â”œâ”€ DataTransform7.R
â”‚  â”‚  â”œâ”€ DataTransform8.R
â”‚  â”‚  â”œâ”€ DataTransform9.R
â”‚  â”‚  â”œâ”€ DataTransform10.R
â”‚  â”‚  â”œâ”€ DataTransform11.R
â”‚  â”‚  â”œâ”€ DataTransform12.R
â”‚  â”‚  â”œâ”€ readme.txt
â”‚  â””â”€ transform_info.txt
â”‚  â”‚
â”‚  â””â”€ (other feature scripts live here)
â”‚
â”œâ”€ MODEL/
â”‚  â””â”€ model1.ipynb                    # CV by year, OOF calibration, holdâ€‘out 2023â€“2025
â”‚
â”œâ”€ LICENSE
â””â”€ README.md                          # You are here
```

> **Note on dates file**: the rankings fetcher uses `fechas.txt` populated directly from ATP HTML. Example lines present in that file (as found in source pages):
> `<option value="2025-09-22">2025.09.22</option>`
> `<option value="2025-09-15">2025.09.15</option>`
> â€¦the **`value`** field is parsed as `YYYY-mm-dd`.

---

## ğŸ§ª Pipeline at a glance

```
  A[Ranking_scrapping.py (headless)] --> B[raw HTML (.txt per date)]
  B --> C[rankings_to_csv.py (BeautifulSoup)]
  C --> D[SQL Staging (Tables/ Staging/)]
  D --> E[Procedures & Functions (sf_*/sp_*)]
  E --> F[Views (vw_atp_matches, vw_player_stats)]

  %% Python ETL extractors run AFTER SQL creation (all run by runner.py)
  F --> X1[ETL/Extractor/TournamentsATPExtractor.py]
  X1 --> X2[ETL/Extractor/PlayersATPExtractor.py]
  X2 --> X3[ETL/Extractor/MatchesATPExtractor.py]
  X3 --> X4[ETL/Extractor/StatsATPExtractor.py]

  X4 --> G[CreateData.R & DataTransform*.R]
  G --> H[Final enriched dataset]
  H --> I[MODEL/model1.ipynb â€” XGBoost]
  I --> J[CV by year + OOF calibration + holdâ€‘out]
```

### 1) Scraping & Parsing

**A. Core HTML Extractors (Python)**
Located in `ETL/Extractor/`, these modules perform the **primary data extraction from ATP web pages (HTML scraping)** and normalize outputs for staging:

* `ETL/Extractor/base_extractor.py` & `ETL/Extractor/constants.py` â€” shared session, headers, retries/backoff, helpers, and constants (URLs, paths, regexes). Designed for polite scraping.
* `ETL/Extractor/MatchesATPExtractor.py` â€” crawls & parses match pages/feeds and prepares match-level records.
* `ETL/Extractor/PlayersATPExtractor.py` â€” extracts player pages (bio/handedness/backhand, country, etc.).
* `ETL/Extractor/TournamentsATPExtractor.py` â€” pulls tournament metadata (location, surface, category, indoor/outdoor).
* `ETL/Extractor/StatsATPExtractor.py` â€” scrapes stats blocks where available and aligns them to match IDs/players.

> **Notes:** Extractors follow a "fetch â†’ parse (BeautifulSoup) â†’ normalize" pattern. Raw HTML/JSON can be cached locally to make runs reproducible and to minimize load on the origin.

**B. Rankings Scrapers (headless) + Parser**

* `Transform/Ranking Scrapping/Ranking_scrapping.py` â€” downloads **official ATP rankings HTML** in **headless mode** and stores full HTML as text (`rankings_YYYY-mm-dd.txt`).
  *This design is deliberate:* saving raw HTML first makes the pipeline **finite and reproducible**; you can reâ€‘parse locally without revisiting the site.
* `Transform/Ranking Scrapping/rankings_to_csv.py` â€” parses those files and extracts **`ranking`** and **`player_code`** per date (robust to absolute/relative URLs and locale prefixes like `/es/`, `/en/`).

---

### 2) SQL Staging & Business Logic

* **Tables** under `ETL/SQL/Tables/Staging/` define the staging schema: `atp_matches.sql`, `atp_matches_enriched.sql`, `atp_players.sql`, `atp_tournaments.sql`, `points_rulebook.sql`, `surfaces.sql`, etc.
* **Procedures & functions** under `ETL/SQL/Procedures&Functions/` (files beginning with `sf_` / `sp_`) implement:

  * Delta and hash logic for incremental loads (`*_delta_hash.sql`).
  * Player points rules application & enrichment (`sp_apply_points_rules.sql`, `sp_calculate_player_points.sql`, `sp_enrich_atp_matches.sql`).
  * Merge/processing orchestration for matches, players, tournaments (e.g., `sp_merge_atp_players.sql`, `sp_process_atp_matches.sql`).
* **Views** in `ETL/SQL/views/` expose analyticsâ€‘ready joins: `vw_atp_matches.sql`, `vw_player_stats.sql`.

---

### 3) ETL / Feature Engineering (R)

* `ETL/Load/CreateData.R` and the series of `Transform/Ranking Scrapping/DataTransform*.R` scripts stitch everything into a **matchâ€“player** panel.
* Feature highlights (mirrored for `player_*` and `opponent_*`):

  * **Rest & load:** `*_days_since_prev_tournament`, `*_weeks_since_prev_tournament`, `*_prev_tour_matches`.
  * **Adaptation flags:** `*_country_changed`, `*_continent_changed`, `*_surface_changed`, `*_indoor_changed`.
  * **Fatigue proxies:** `*_back_to_back_week`, `*_two_weeks_gap`, `*_long_rest`, `*_red_eye_risk`, `*_travel_fatigue`.

---

### 4) Modeling (Python, Jupyter)

* `MODEL/model1.ipynb` implements:

  * `ColumnTransformer` (sparse **Oneâ€‘Hot** for categoricals, numeric coercion to `float32`).
  * **XGBoost** (`tree_method=hist`) with early stopping.
  * **CV by year (2000â€“2025)** with **`id` grouping** (both rows of a match stay together).
  * **OOF 2000â€“2022** for **isotonic calibration**.
  * **Holdâ€‘out 2023â€“2025** with breakdowns by tournament type and a **costâ€‘optimal threshold** utility.

---

## ğŸ’ The dataset (the crown jewel)

* **Coverage**: 1999â€“2025 (with preâ€‘1999 seeds where applicable).
* **Unit**: **matchâ€“player** rows (two rows per match), with mirrored `player_*` / `opponent_*` context for matchâ€‘up modeling.
* **Key examples**:

  * `player_days_since_prev_tournament`, `opponent_days_since_prev_tournament`
  * `player_red_eye_risk`, `opponent_red_eye_risk`
  * `player_travel_fatigue`, `opponent_travel_fatigue`
  * `player_prev_tour_matches`, `player_prev_tour_max_round` (and mirrored opponent features)
  * Context: `surface`, `indoor_outdoor`, `best_of`, `tournament_country`, `tournament_category`, ranking trends, home flags, etc.
* **Ready for ML/BI**: clean column types, temporal safety, longâ€‘term consistency.

---

# ğŸš€ Quickstart

> Assumes **Python 3.10+**, **R 4.2+**, and isolated envs (conda/venv).

---

## 1) Clone

```bash
git clone https://github.com/Aitor-Quint-04/ATP-Match-Outcome-Prediction.git
cd ATP-Match-Outcome-Prediction
```

## 2) Install Python deps 

```bash
python -m pip install -U pandas numpy scipy scikit-learn xgboost beautifulsoup4 lxml selenium
# Optional: easy driver management
python -m pip install -U webdriver-manager
```

## 3) Fetch rankings HTML & parse

```bash
python "Transform/Ranking Scrapping/Ranking_scrapping.py"
python "Transform/Ranking Scrapping/rankings_to_csv.py"
```

## 4) Create staging & run SQL logic

Load the scripts in this order:

1. `ETL/SQL/Tables/Staging/` (tables)
2. `ETL/SQL/Procedures&Functions/` (procedures/functions)
3. `ETL/SQL/views/` (views)

## 5) Run Python ETL extractors (in order)

> Run from the repo root so relative imports/config resolve correctly.

```bash

# 0) Run dependencies
python "ETL/Extractor/base_extractor.py"
python "ETL/Extractor/constants.py"
python "ETL/Extractor/MatchesBaseExtractor.py"

# 1) Tournaments
python "ETL/Extractor/TournamentsATPExtractor.py"

# 2) Players
python "ETL/Extractor/PlayersATPExtractor.py"

# 3) Matches
python "ETL/Extractor/MatchesATPExtractor.py"

# 4) Stats
python "ETL/Extractor/StatsATPExtractor.py"

# 5) Run the extractor (check the code)
pyton "ETL/Extractor/runner.py"

```

## 6) Assemble features (R)

```r
# In R
source("ETL/Load/CreateData.R")
# or run the DataTransform*.R scripts inside Transform/Ranking Scrapping/
```

### 6â€‘bis) Full R transformation pipeline (stepâ€‘byâ€‘step)

All transformation scripts live in **`Transform/Ranking Scrapping/`** and are designed to run **sequentially**. They progressively build the final **matchâ€“player panel** (two rows per match) with mirrored `player_*` / `opponent_*` context.

> Required packages (typical): `data.table`, `dplyr`, `readr`, `stringr`, `lubridate`, `tidyr`, `purrr`. Install as needed.

**Script responsibilities (by file):**

**(read the codes doc)**

1. **`DataTransform1.R`** â€“ Base normalization

   * Coerce types, standardize column names, parse `tournament_start_dtm`, rounds and match order.
   * Normalize keys and fix minor inconsistencies.
  
     **...**

2. **`DataTransform3.R`** â€“ Geography & context

   * Country â†’ continent mapping; indoor/outdoor normalization.
   * Surface harmonization (clay/hard/grass); stadium metadata if required.

     **...**

3. **`DataTransform5.R`** â€“ Rankings join

   * Merge perâ€‘date rankings (from scraping) into matches by player and date.
   * Create ranking trend features (e.g., 4w/12w deltas if available).
  
     **...**

15. **`DataTransformFINAL.R`** 

    * Write the longâ€‘horizon enriched dataset (e.g., `database_99-25_1.csv`).
    * Bayesian Smooth
    * Correlation analysis

> Notes
>
> * `ETL/Load/CreateData.R` can orchestrate or prepare inputs.
> * Intermediate artifacts (if any) are written under your configured output directory.

### Oneâ€‘shot runner for all R transforms

Use this snippet to execute the transforms **in the right order** (explicitly lists `5_1` and `6_1` to avoid alphanumeric sorting issues):

```r
# ---- packages (install if needed) ----
req <- c("data.table","dplyr","readr","stringr","lubridate","tidyr","purrr","zoo","progress","roll")
new <- setdiff(req, rownames(installed.packages()))
if (length(new)) install.packages(new)
invisible(lapply(req, library, character.only = TRUE))

# ---- paths ----
ROOT <- getwd()  # run from repo root
SCRIPTS <- file.path

order <- c(
  "Transform/Ranking Scrapping/DataTransform1.R",
  "Transform/Ranking Scrapping/DataTransform2.R",
  "Transform/Ranking Scrapping/DataTransform3.R",
  "Transform/Ranking Scrapping/DataTransform4.R",
  "Transform/Ranking Scrapping/DataTransform5.R",
  "Transform/Ranking Scrapping/DataTransform5_1.R",
  "Transform/Ranking Scrapping/DataTransform6.R",
  "Transform/Ranking Scrapping/DataTransform6_1.R",
  "Transform/Ranking Scrapping/DataTransform7.R",
  "Transform/Ranking Scrapping/DataTransform8.R",
  "Transform/Ranking Scrapping/DataTransform9.R",
  "Transform/Ranking Scrapping/DataTransform10.R",
  "Transform/Ranking Scrapping/DataTransform11.R",
  "Transform/Ranking Scrapping/DataTransform12.R"
)

for (s in order) {
  cat(sprintf("\n>>> Running: %s\n", s))
  source(s, echo = TRUE, max.deparse.length = Inf)
}

cat("\nAll transforms finished. Check the exported dataset (e.g., database_99-25_1.csv).\n")
```

---

## 7) Model

Open **`MODEL/model1.ipynb`** and run all cells to reproduce: **CV by year**, **OOF calibration**, and **holdâ€‘out 2023â€“2025**.

> A tiny sample lives in `Data_Example/sample.csv` for quick sanity checks.

---

## ğŸ§° Practical tips

* **Separate download & parsing**: save HTML once, parse many timesâ€”faster and kinder to the origin.
* **Avoid leakage**: never fit the preprocessor on validation folds; the notebook uses perâ€‘fold clones.
* **Use the costâ€‘optimal threshold**: when decisions carry asymmetric costs, tune `cost_fp`/`cost_fn` and deploy `thr*`.

---

## âš ï¸ Data & ethics

* **Scraping** must follow the source siteâ€™s **Terms of Use**, **robots.txt**, and reasonable rate limits.
* This repo is for **research/educational** purposes. Youâ€™re responsible for compliance and downstream use.
* **Not betting advice.** If you operate in betting contexts, understand legal constraints, risk management, and calibration needs.

---

## ğŸ—ºï¸ Roadmap

* [ ] Export the **final dataset** in partitioned Parquet with a full **data dictionary**.
* [ ] Minimal **feature store** (ETL versioning + artifact registry).
* [ ] Additional baselines (Logistic, CatBoost, LightGBM) + **ensembles**.
* [ ] Drift monitoring by season and tournament type.
* [ ] Lightweight API for serving **calibrated probabilities** in real time.

---

## ğŸ¤ Contributing

Ideas, PRs and issues are very welcome! If you propose new features, please **motivate the sports mechanism** youâ€™re capturing and include **outâ€‘ofâ€‘sample evidence**.

---

## ğŸ“„ License

Code under a permissive open license (see `LICENSE`).
Please also review the terms that apply to any **source data** you use.

---

## ğŸ¯ TL;DR

This project combines **robust ETL**, **contextâ€‘rich competitive features**, and a **calibrated XGBoost** with metrics that **generalize**.
The **dataset is the crown jewel**: deep, consistent and ready to power serious **sports analytics**â€”from research to production.
